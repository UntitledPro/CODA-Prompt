************************************
* STARTING TRIAL 1
************************************
Files already downloaded and verified
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
ortho penalty is on
Prompt strategy:  int
*****************************************
====================== 1 =======================
Incremental class: Old valid output dimension: 0
Incremental class: New Valid output dimension: 10
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 2.775 | Train Acc 65.625
LR: 0.001
Epoch:2/10
 * Loss 1.017 | Train Acc 88.141
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.583 | Train Acc 92.348
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.436 | Train Acc 92.929
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.376 | Train Acc 93.029
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.326 | Train Acc 93.470
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.320 | Train Acc 93.009
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.290 | Train Acc 93.770
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.287 | Train Acc 93.770
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.268 | Train Acc 94.391
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-1/
=> Save Done
validation split name: 1
 * Val Acc 99.000, Total time 5.26
====================== 2 =======================
Incremental class: Old valid output dimension: 10
Incremental class: New Valid output dimension: 20
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.997 | Train Acc 78.005
LR: 0.001
Epoch:2/10
 * Loss 0.651 | Train Acc 90.725
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.497 | Train Acc 91.226
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.420 | Train Acc 92.368
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.400 | Train Acc 91.747
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.355 | Train Acc 92.728
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.333 | Train Acc 93.029
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.335 | Train Acc 92.428
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.325 | Train Acc 92.408
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.333 | Train Acc 92.348
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-2/
=> Save Done
validation split name: 1
 * Val Acc 97.500, Total time 6.04
validation split name: 2
 * Val Acc 95.600, Total time 5.99
====================== 3 =======================
Incremental class: Old valid output dimension: 20
Incremental class: New Valid output dimension: 30
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.803 | Train Acc 78.125
LR: 0.001
Epoch:2/10
 * Loss 0.569 | Train Acc 91.166
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.420 | Train Acc 92.067
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.370 | Train Acc 91.787
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.345 | Train Acc 92.328
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.310 | Train Acc 93.109
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.318 | Train Acc 92.308
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.297 | Train Acc 93.510
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.294 | Train Acc 92.748
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.266 | Train Acc 93.610
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-3/
=> Save Done
validation split name: 1
 * Val Acc 95.900, Total time 5.86
validation split name: 2
 * Val Acc 91.300, Total time 6.05
validation split name: 3
 * Val Acc 94.600, Total time 6.11
====================== 4 =======================
Incremental class: Old valid output dimension: 30
Incremental class: New Valid output dimension: 40
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.655 | Train Acc 79.728
LR: 0.001
Epoch:2/10
 * Loss 0.522 | Train Acc 92.668
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.406 | Train Acc 92.648
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.339 | Train Acc 93.810
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.315 | Train Acc 93.610
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.310 | Train Acc 93.470
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.279 | Train Acc 93.930
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.281 | Train Acc 93.750
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.252 | Train Acc 94.491
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.261 | Train Acc 93.790
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-4/
=> Save Done
validation split name: 1
 * Val Acc 95.000, Total time 6.73
validation split name: 2
 * Val Acc 83.900, Total time 6.08
validation split name: 3
 * Val Acc 89.600, Total time 5.98
validation split name: 4
 * Val Acc 96.400, Total time 6.07
====================== 5 =======================
Incremental class: Old valid output dimension: 40
Incremental class: New Valid output dimension: 50
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.659 | Train Acc 76.262
LR: 0.001
Epoch:2/10
 * Loss 0.513 | Train Acc 90.725
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.397 | Train Acc 91.747
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.334 | Train Acc 92.929
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.294 | Train Acc 93.349
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.278 | Train Acc 93.329
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.275 | Train Acc 93.029
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.242 | Train Acc 94.311
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.262 | Train Acc 92.989
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.239 | Train Acc 93.970
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-5/
=> Save Done
validation split name: 1
 * Val Acc 93.400, Total time 6.26
validation split name: 2
 * Val Acc 84.400, Total time 6.34
validation split name: 3
 * Val Acc 83.500, Total time 6.21
validation split name: 4
 * Val Acc 90.200, Total time 5.96
validation split name: 5
 * Val Acc 95.500, Total time 5.87
====================== 6 =======================
Incremental class: Old valid output dimension: 50
Incremental class: New Valid output dimension: 60
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.655 | Train Acc 77.264
LR: 0.001
Epoch:2/10
 * Loss 0.473 | Train Acc 90.645
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.375 | Train Acc 91.667
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.335 | Train Acc 91.947
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.312 | Train Acc 91.967
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.292 | Train Acc 92.488
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.274 | Train Acc 92.748
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.270 | Train Acc 92.508
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.257 | Train Acc 93.009
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.260 | Train Acc 92.468
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-6/
=> Save Done
validation split name: 1
 * Val Acc 94.000, Total time 6.34
validation split name: 2
 * Val Acc 83.000, Total time 6.38
validation split name: 3
 * Val Acc 85.600, Total time 6.26
validation split name: 4
 * Val Acc 87.400, Total time 6.10
validation split name: 5
 * Val Acc 89.300, Total time 6.09
validation split name: 6
 * Val Acc 93.200, Total time 6.13
====================== 7 =======================
Incremental class: Old valid output dimension: 60
Incremental class: New Valid output dimension: 70
Optimizer is reset!
*****************************************
LR: 0.001
Epoch:1/10
 * Loss 1.696 | Train Acc 73.558
LR: 0.001
Epoch:2/10
 * Loss 0.517 | Train Acc 89.443
LR: 0.0009851093261547738
Epoch:3/10
 * Loss 0.395 | Train Acc 91.006
LR: 0.0009408807689542254
Epoch:4/10
 * Loss 0.355 | Train Acc 91.426
LR: 0.0008686315144381912
Epoch:5/10
 * Loss 0.313 | Train Acc 92.188
LR: 0.0007705132427757892
Epoch:6/10
 * Loss 0.303 | Train Acc 92.368
LR: 0.0006494480483301837
Epoch:7/10
 * Loss 0.286 | Train Acc 92.268
LR: 0.0005090414157503712
Epoch:8/10
 * Loss 0.284 | Train Acc 92.047
LR: 0.00035347484377925713
Epoch:9/10
 * Loss 0.251 | Train Acc 93.249
LR: 0.00018738131458572452
Epoch:10/10
 * Loss 0.250 | Train Acc 93.209
=> Saving class model to: outputs/cifar-100/10-task/int_verbose_hint-int-8-newsim-rand10/models/repeat-1/task-7/
=> Save Done
validation split name: 1
Traceback (most recent call last):
  File "run.py", line 257, in <module>
    avg_metrics = trainer.train(avg_metrics)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/trainer.py", line 265, in train
    acc_table.append(self.task_eval(j))
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/trainer.py", line 173, in task_eval
    return self.learner.validation(test_loader, task_metric=task)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/learners/default.py", line 185, in validation
    output = model.forward(input)[:, :self.valid_out_dim]
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/_utils.py", line 461, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/models/verbose.py", line 886, in forward
    glob_x = torch.cat(
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/models/vit.py", line 308, in forward
    x = blk(x, register_blk == i, prompt=p_list)
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/models/vit.py", line 158, in forward
    x = x + self.drop_path(self.mlp(self.norm2(x)))
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jiashuo/workspace/codes/CONTINUAL_LEARNING/CODA-Prompt/models/vit.py", line 39, in forward
    x = self.act(x)
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jiashuo/env/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 681, in forward
    return F.gelu(input, approximate=self.approximate)
RuntimeError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.69 GiB total capacity; 6.50 GiB already allocated; 14.94 MiB free; 6.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

